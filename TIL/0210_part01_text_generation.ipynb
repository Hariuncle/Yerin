{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THz7hp89CrEI"
      },
      "source": [
        "# 생성 모델을 위한 딥러닝\n",
        "- Augmented Intelligence(확장된 지능)\n",
        "  - AI가 사람의 능력을 증가시키는 도구로 사용\n",
        "- 예술 창작의 대부분은 간단한 패턴 인식과 기교로 구성됨\n",
        "  - 사람의 지각, 언어, 예술 작품 모두 통계적 구조\n",
        "  - 딥러닝은 이런 구조, 즉 latent space(잠재 공간)를 학습하는 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBnsAPKECrEI"
      },
      "source": [
        "## 텍스트 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D89JwqPBCrEJ"
      },
      "source": [
        "### 시퀀스 생성을 위한 딥러닝 모델의 간단한 역사"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4P5rIr6CrEJ"
      },
      "source": [
        "### 시퀀스 데이터를 어떻게 생성할까?\n",
        "- 시퀀스 데이터를 생성하는 일반적인 방법\n",
        "  - 이전 토큰을 입력으로 사용해서 시퀀스의 다음 1개 또는 몇 개의 토큰을 트랜스포머나 RNN으로 예측\n",
        "- Language Model\n",
        "  - 이전 토큰(단어 혹은 글자)들이 주어졌을 때 다음 토큰의 확률을 모델링할 수 있는 네트워크\n",
        "  - 언어의 통계적 구조인 잠재 공간을 탐색\n",
        "- 모델이 훈련하고 나면 해당 모델에서 샘플링 가능 : 새로운 시퀀스 생성\n",
        "  - 초기 텍스트 문자열을 주입 (conditioning data)\n",
        "  - 새로운 글자나 단어를 생성 (여러 개도 ㄱㅊ)\n",
        "  - 생성된 출력은 다시 입력 데이터로 추가\n",
        "  - 반복\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBs8uChTCrEJ"
      },
      "source": [
        "### 샘플링 전략의 중요성\n",
        "- Greedy sampling\n",
        "  - 엔트로피가 최소\n",
        "  - 반복적이고 예상 가능한 문자열\n",
        "- Stochastic sampling\n",
        "  - 무작위성(random) 주입\n",
        "  - 엔트로피가 높음\n",
        "    - 근데 엔트로피가 최대인 경우 : 완전히 무작위, 모든 단어의 확률이 같음 -> 별로 안 흥미로움 -> 적당히 softmax 출력을 사용하자\n",
        "  - Softmax 출력, 실제 모델의 확률 분포에서 샘플링하는게 엔트로피가 최소, 최대 두 지점에 사이인거\n",
        "- Softmax temperature 파라미터\n",
        "  - 샘플링 과정에서 확률의 양을 조절\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMcqO4_VCrEK"
      },
      "source": [
        "**다른 온도 값을 사용하여 확률 분포의 가중치 바꾸기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "baD0AHOUCrEK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# original_distribution : 전체 합이 1인 1D numpy array\n",
        "# temperature : 출력 분포의 엔트로피 양을 결정\n",
        "def reweight_distribution(original_distribution, temperature=0.5):\n",
        "    # 원본 분포의 가중치를 변경\n",
        "    distribution = np.log(original_distribution) / temperature\n",
        "    distribution = np.exp(distribution)\n",
        "    # 새로 바꾼 분포의 합이 1이 아닐 수도 있으니, 새로운 분포의 합으로 나눠줌\n",
        "    return distribution / np.sum(distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hCKGeqJCrEL"
      },
      "source": [
        "### 케라스를 사용한 텍스트 생성 모델 구현\n",
        "- IMDB 영화 리뷰 데이터셋 사용\n",
        "- 리뷰 생성 : 스타일과 주제를 모델링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmTMyS1ZCrEM"
      },
      "source": [
        "#### 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM6Umf4uCrEM"
      },
      "source": [
        "**IMDB 영화 리뷰 데이터셋 다운로드하고 압축 풀기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS_z2t7PCrEN",
        "outputId": "b4228a5e-e875-41b9-fd3e-c6a5242d5b44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-10 05:59:14--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  51.4MB/s    in 1.6s    \n",
            "\n",
            "2025-02-10 05:59:15 (51.4 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcHe7T_QCrEN"
      },
      "source": [
        "**텍스트 파일(한 파일 = 한 샘플)에서 데이터셋 만들기**  \n",
        "- `label_mode=None`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb2YjZ86CrEO",
        "outputId": "547167b9-6f44-4f8c-e30a-2f7733f6aa15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100006 files.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "dataset = keras.utils.text_dataset_from_directory(\n",
        "    directory=\"aclImdb\", label_mode=None, batch_size=256)\n",
        "dataset = dataset.map(lambda x: tf.strings.regex_replace(x, \"<br />\", \" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-6pyZNQCrEO"
      },
      "source": [
        "**`TextVectorization` 층 준비하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aHTeHqNfCrEO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "sequence_length = 100\n",
        "# 가장 많이 등장하는 15000개 단어만 사용\n",
        "# 그 외는 OOV 토큰인 \"[UNK]\"으로 처리\n",
        "vocab_size = 15000\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    # 정수 단어 인덱스의 시퀀스를 반환\n",
        "    output_mode=\"int\",\n",
        "    # 길이가 100인 input / target\n",
        "    # 근데 타겟은 한 스텝 차이나기 때문에 실제로 모델은 99개의 단어 시퀀스를 봄\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "text_vectorization.adapt(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLhj695ZCrEO"
      },
      "source": [
        "**언어 모델링 데이터셋 만들기**  \n",
        "- Input : Vectorized text\n",
        "- Output : Previous text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pCPsdys6CrEP"
      },
      "outputs": [],
      "source": [
        "def prepare_lm_dataset(text_batch):\n",
        "    vectorized_sequences = text_vectorization(text_batch)\n",
        "    # 시퀀스의 마지막 단어를 제외한 입력\n",
        "    x = vectorized_sequences[:, :-1]\n",
        "    # 시퀀스의 첫 단어를 제외한 타겟\n",
        "    y = vectorized_sequences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "lm_dataset = dataset.map(prepare_lm_dataset, num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZDJxIp9CrEP"
      },
      "source": [
        "#### 트랜스포머 기반의 시퀀스-투-시퀀스 모델\n",
        "- 훈련 : 초기 몇 개의 단어가 주어지면 문장의 다음 단어에 대한 확률 분포를 예측하는 모델 훈련\n",
        "  - 초기 문장을 주입\n",
        "  - 다음 단어를 샘플링하여 해당 문장에 추가\n",
        "  - 짧은 문단을 생성할 때까지 반복\n",
        "- 문제점\n",
        "  - N개의 단어로 예측을 만드는 방법을 학습하지만, N개보다 적은 단어로 예측을 시작할 수 있어야 함\n",
        "  - 훈련에 사용하는 많은 시퀀스는 중복\n",
        "- 해결 방법 : Seq-to-seq 모델 사용\n",
        "  - 단어 N개의 시퀀스를 모델에 주입, 한 스텝 다음의 시퀀스를 예측\n",
        "  - Causal masking을 사용하여 어떤 인덱스 i에서 모델은 0에서 i까지 단어만 사용해서 i+1번째 단어를 예측\n",
        "  - 즉, 1 <= i <= N 인 단어의 시퀀스에서 다음 단어를 예측\n",
        "  - 따라서, 생성 단계에서는 하나의 단어만 모델에 전달해도 다음 단어에 대한 확률 분포를 만들 수 있음\n",
        "- Seq-to-Seq\n",
        "  - 소스 시퀀스를 인코더에 주입\n",
        "  - 인코딩된 시퀀스와 타겟 시퀀스를 디코더로 전달\n",
        "  - 한 스텝 후의 타겟 시퀀스 예측\n",
        "- 근데 텍스트 생성에서는 소스 시퀀스가 없음\n",
        "  - 과거 토큰이 주어지면 타겟 시퀀스에 있는 다음 토큰을 예측하는 것뿐\n",
        "  - 따라서 디코더만 사용해서 수행\n",
        "  - Causal padding으로 인해 디코더는 단어 0부터 N만 사용해서 N + 1를 예측 가능\n",
        "- 11장에서 만든 `PositionalEmbedding`과 `TransformerDecoder`를 재사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "O40uNWAWCrEP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class NotEqualLayer(keras.Layer):\n",
        "    def call(self, x):\n",
        "        return tf.math.not_equal(x, 0)\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return NotEqualLayer()(inputs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "          num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "          num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(TransformerDecoder, self).get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    # def get_causal_attention_mask(self, inputs):\n",
        "    #     input_shape = tf.shape(inputs)\n",
        "    #     batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "    #     i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "    #     j = tf.range(sequence_length)\n",
        "    #     mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "    #     mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "    #     mult = tf.concat(\n",
        "    #         [tf.expand_dims(batch_size, -1),\n",
        "    #          tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "    #     return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        # causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        # if mask is not None:\n",
        "        #     padding_mask = tf.cast(\n",
        "        #         mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "        #     padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            use_causal_mask=True)\n",
        "            # attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs\n",
        "            # attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qO94YIGCrEQ"
      },
      "source": [
        "**간단한 트랜스포머 기반 언어 모델**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LGCHdjUqCrEQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 2\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, x)\n",
        "# 출력 시퀀스 타임스텝마다 가능한 어휘 사전의 단어에 대해\n",
        "# 소프트맥스 확률을 계산\n",
        "outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXrXEm3ICrEQ"
      },
      "source": [
        "### 가변 온도 샘플링을 사용한 텍스트 생성 콜백\n",
        "- 콜백을 사용하여 에포크가 끝날 때마다 다양한 온도로 텍스트를 생성\n",
        "- 모델이 수렴하면서 생성된 텍스트가 어떻게 발전하는지 온도가 샘플링 전략에 미치는 영향 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeARJmFICrEQ"
      },
      "source": [
        "**텍스트 생성 콜백**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RtzXqzI1CrER"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 단어 인덱스를 문자열로 매핑하는 딕셔너리\n",
        "# 텍스트 디코딩에 사용\n",
        "tokens_index = dict(enumerate(text_vectorization.get_vocabulary()))\n",
        "\n",
        "# 어떤 확률 분포에 대한 가변 온도 샘플링을 구현\n",
        "def sample_next(predictions, temperature=1.0):\n",
        "    predictions = np.asarray(predictions).astype(\"float64\")\n",
        "    predictions = np.log(predictions) / temperature\n",
        "    exp_preds = np.exp(predictions)\n",
        "    predictions = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, predictions, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "class TextGenerator(keras.callbacks.Callback):\n",
        "    def __init__(self,\n",
        "                 prompt,             # 텍스트 생성을 위한 시작 문장\n",
        "                 generate_length,    # 생성할 단어 개수\n",
        "                 model_input_length,\n",
        "                 temperatures=(1.,), # 샘플링에 사용할 온도 범위\n",
        "                 print_freq=1):\n",
        "        self.prompt = prompt\n",
        "        self.generate_length = generate_length\n",
        "        self.model_input_length = model_input_length\n",
        "        self.temperatures = temperatures\n",
        "        self.print_freq = print_freq\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.print_freq != 0:\n",
        "            return\n",
        "        for temperature in self.temperatures:\n",
        "            print(\"== Generating with temperature\", temperature)\n",
        "            # 시작 단어에서부터 텍스트 생성\n",
        "            sentence = self.prompt\n",
        "            for i in range(self.generate_length):\n",
        "                # 현재 시퀀스를 모델에 주입\n",
        "                tokenized_sentence = text_vectorization([sentence])\n",
        "                predictions = self.model(tokenized_sentence)\n",
        "                # 마지막 타임스텝의 예측을 추출하여 다음 단어를 샘플링\n",
        "                next_token = sample_next(predictions[0, i, :], temperature)\n",
        "                sampled_token = tokens_index[next_token]\n",
        "                # 새로운 단어를 현재 시퀀스에 추가하고 반복\n",
        "                sentence += \" \" + sampled_token\n",
        "            print(sentence)\n",
        "\n",
        "prompt = \"This movie\"\n",
        "text_gen_callback = TextGenerator(\n",
        "    prompt,\n",
        "    generate_length=50,\n",
        "    model_input_length=sequence_length,\n",
        "    # 텍스트 샘플링에 다양한 온도를 사용하여 텍스트 생성에 미치는 온도의 영향을 확인\n",
        "    temperatures=(0.2, 0.5, 0.7, 1., 1.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZIt8p-oCrER"
      },
      "source": [
        "**언어 모델 훈련하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PeBx-DacCrER",
        "outputId": "8033ae29-b567-4128-8bb9-9624d6177ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: 6.3848== Generating with temperature 0.2\n",
            "This movie is is a a very [UNK] good [UNK] movie [UNK] is [UNK] a [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "== Generating with temperature 0.5\n",
            "This movie is is a a decent child movie and is i a was couple not of so the much best like [UNK] [UNK] the [UNK] [UNK] and and the they [UNK] are [UNK] all and the [UNK] movie [UNK] is are a the little [UNK] girl woman who who wants is\n",
            "== Generating with temperature 0.7\n",
            "This movie is is one [UNK] of and an 1962 cheated is for a [UNK] [UNK] of [UNK] a [UNK] great [UNK] film and you [UNK] ever cinematography made and by uninspired king for than [UNK] the [UNK] music the style [UNK] was is not not only seen thing in about a\n",
            "== Generating with temperature 1.0\n",
            "This movie was is and just although plain the already jokes should were be popular able split to two jewel tv and and laughed donald perverted luther productions harris i although noticed they chicken are answers purpose to for his a little woman girl on plays victims by its mad still wealthy\n",
            "== Generating with temperature 1.5\n",
            "This movie stefan all staying surprises himself 2 debt womens spy ernst reported dd male note morgue when whose has masters afterwards who continuity give because down the that bud go emotionless disgusted kathleen thriller marvelous firmly jerky from mason it shack bacall were faked showing underground insane dialog drama into wrote\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 462ms/step - loss: 6.3836\n",
            "Epoch 2/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 5.5023== Generating with temperature 0.2\n",
            "This movie movie is is a a great very movie good that movie it is is a a [UNK] very and good it movie is is a a great good movie movie that is is a a very movie good that movie is is a a very great good movie movie is\n",
            "== Generating with temperature 0.5\n",
            "This movie movie is is good one but of its the very worst very movies good that job is i about have the been acting a is good a moments bad of the the plot story was is not a very movie good is idea that of this the one movie of\n",
            "== Generating with temperature 0.7\n",
            "This movie is was its a a group very of good the movie pleasant that movie you it need is like a for movie the is graphics still were [UNK] a and movie in its the worth film seeing is this it movie for is my funny list and of the the\n",
            "== Generating with temperature 1.0\n",
            "This movie movie has made every me time to for be the about first five two minutes and of you cool the on american things but take overall looks [UNK] like [UNK] an and island dog in pickup this film movie is gets not himself resemblance with that your it mind will\n",
            "== Generating with temperature 1.5\n",
            "This movie is like present luck mean fantasy brad and newspapers why only chant bloodbath spooky live many furry stupid darwin disjointed faults emily daphne logic sad and thrills carlyle his understanding spark considering commentary 27 the dark water photography live 20 hotel humor still choices achieved ryan marco jungle trilogy crowd\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 405ms/step - loss: 5.5022\n",
            "Epoch 3/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 5.3380== Generating with temperature 0.2\n",
            "This movie is is a a great very movie good and movie a  great movie i love it is very good and the movie                           \n",
            "== Generating with temperature 0.5\n",
            "This movie movie is is one a of [UNK] the  worst movie i have ever seen it    and    and    and and and  and  i and  i and  this          \n",
            "== Generating with temperature 0.7\n",
            "This movie film is and not the be most the boring acting even is the the performance only and good it the is movie considered this the is movie the is worst sweet movie the  plot is they should be a scary as the script maybe we are so the acting\n",
            "== Generating with temperature 1.0\n",
            "This movie show was a a horrible pointless special disappointment visually this hilarious movie and  its a good wedding movie still outdated and the ending rusty and depressing to possess when it is truly a budget is horrible things feel the camera terrorist woman suddenly goes into your last retire that\n",
            "== Generating with temperature 1.5\n",
            "This movie director easily was made mostly as reciting well drama combined kids with not what there else ice its sorry get for meaning hisher food blind from producer rogue may spirit have this and superbly fatally bad basic for worst tone film for perhaps shtick try her to neck amsterdam puppies\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 407ms/step - loss: 5.3379\n",
            "Epoch 4/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 5.2336== Generating with temperature 0.2\n",
            "This movie is is a a great great movie movie and  the best movie  i and i and and and i and and i i i and and i i i i i i i i i i i i i i i i i i i i i i\n",
            "== Generating with temperature 0.5\n",
            "This movie movie is is a a great great movie movie it it is is very not good the and movie [UNK] and  is a [UNK]  the and i and i and i movie and and i i i i and and i i i and i i i i\n",
            "== Generating with temperature 0.7\n",
            "This movie movie is is a very great good   to and  it and this and the it in to and and it movie and in and this there and i to and to if i to i to to there i but to to i i of and i\n",
            "== Generating with temperature 1.0\n",
            "This movie movie is was probably really the the end sad of and the it performances it wilson is who just once a the rather dialogue [UNK] and yeah it it  a very good  it and but the not the for but the they to i i i but i\n",
            "== Generating with temperature 1.5\n",
            "This movie written chan [UNK] sucks version you rather cringe recommendation the up alternative probably box never muscle holidays knew under how almost could spend corn 1939 computer rain [UNK] crisis is has full delighted abuse to believe nearly the encountered journey exact chain dead thai clear general pure there suspicious is\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 410ms/step - loss: 5.2336\n",
            "Epoch 5/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 5.1576== Generating with temperature 0.2\n",
            "This movie is is a a great great movie movie it and is the a story great of movie the and story the is story very is very very good good and and the the characters movie are is very very good good and and the the movie movie is is very\n",
            "== Generating with temperature 0.5\n",
            "This movie is is a a great movie movie for and the an movie excellent like and a the great movie  i recommend this movie is very good acting is a great movie and the story is a great movie is very well  and of to i this the i\n",
            "== Generating with temperature 0.7\n",
            "This movie movie is is a a great great movie  for the best  of the it the  to well and this to and to and and to  the to to  and to to and movie and i i of and the and this my and i the\n",
            "== Generating with temperature 1.0\n",
            "This movie is was one cast of if the it better for  another musical if you  and the there i what  i to on or and this but around this and i and to to and with i to the you and but dream now and this over i\n",
            "== Generating with temperature 1.5\n",
            "This movie has interwoven sees finished it joanne escapades poetic feature officers gem surfing in action a this great statement performance o that one wayne noir though as this good gray acting hammer cool starring dispose claire into  a conservative roaring behind milland was extremely irritating principle generally working avoiding crazy\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 407ms/step - loss: 5.1576\n",
            "Epoch 6/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 5.0964== Generating with temperature 0.2\n",
            "This movie movie is is a a                                             \n",
            "== Generating with temperature 0.5\n",
            "This movie movie is is a a  movie                                           \n",
            "== Generating with temperature 0.7\n",
            "This movie film is is not great       and                                      \n",
            "== Generating with temperature 1.0\n",
            "This movie was was a a  movie  to      at     parts           concerning              to     everyone \n",
            "== Generating with temperature 1.5\n",
            "This movie film may deserves rapes familys eight bonnie silk thirteen is dispute intended railway to it find acid less certain becoming improves circumstances violence make tibetan number tunes stars dressed with ceremony secretary doug rebecca propaganda freddie ever minds turgid like assassin julie ringing singer although military explicit obsession for among\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 407ms/step - loss: 5.0964\n",
            "Epoch 7/10\n",
            "\u001b[1m352/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14s\u001b[0m 377ms/step - loss: 5.0422"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4e4434f1a741>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 코랩에서 정상 실행만 확인하기 위해 에포크 횟수를 200에서 10으로 줄입니다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(lm_dataset, epochs=10,  # 200\n\u001b[0m\u001b[1;32m      3\u001b[0m           callbacks=[text_gen_callback])\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 코랩에서 정상 실행만 확인하기 위해 에포크 횟수를 200에서 10으로 줄입니다\n",
        "model.fit(lm_dataset, epochs=10,  # 200\n",
        "          callbacks=[text_gen_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_V8gQCWCrER"
      },
      "source": [
        "### 정리\n",
        "- 이전 토큰이 주어지면 다음 토큰들을 예측하는 모델을 훈련하여 시퀀스 데이터를 생성\n",
        "  - 언어 모델 : 단어 / 글자 단위 모두 가능\n",
        "- 모델이 만든 출력에 집중하는 것(엔트로피가 낮음)과 무작위성을 주입하는 것(엔트로피가 높음) 사이에 균형이 중요\n",
        "  - 소프트맥스에 temperature 개념을 도입 (맥스웰-볼츠만 분포 개념)\n",
        "\n",
        "![high_temp.png](./images/high_temp.png)\n",
        "![low_temp.png](./images/low_temp.png)\n",
        "- fn1(x) = log(x)/a , fn2(x) = exp(fn1)\n",
        "  - `a`를 크게 하면 함수의 변화가 완만함 (첫 번째 그림)\n",
        "  - `a`를 작게 하면 함수의 변화가 급격함 (두 번째 그림)\n",
        "- a를 temperature 파라미터로 치환하여 생각\n",
        "```python\n",
        "def reweight_distribution(original_distribution, temperature=0.5):\n",
        "    distribution = np.log(original_distribution) / temperature\n",
        "    distribution = np.exp(distribution)\n",
        "    return distribution / np.sum(distribution)\n",
        "```\n",
        "  - `temperature` 값이 커지면, 즉 온도가 높으면, distribution 이 완만하게 변하여 다양한 값들에 대하여 확률적으로 선택하게 됨 → 무작위성이 높아짐\n",
        "  - `temperature` 값이 작아지면 distribution 이 특정 평균 값 주변으로 narrow하게 변하여 특정 값에 대하여 선택"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "default:Python",
      "language": "python",
      "name": "conda-env-default-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
