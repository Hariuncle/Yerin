{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "df_X = diabetes.data\n",
    "df_y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(df_X)\n",
    "y = np.array(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, W, b):\n",
    "    predictions = 0\n",
    "    for i in range(len(W)):\n",
    "        predictions += X[:, i] * W[i]\n",
    "    predictions += b\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(a, b):\n",
    "    mse = ((a - b) ** 2).mean()  # 두 값의 차이의 제곱의 평균\n",
    "    return mse\n",
    "\n",
    "def loss(X, W, b, y):\n",
    "    predictions = model(X, W, b)\n",
    "    L = MSE(predictions, y)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, W, b, y):\n",
    "    N = len(y)\n",
    "    y_pred = model(X, W, b)\n",
    "    \n",
    "    dW = 1/N * 2 * X.T.dot(y_pred - y)\n",
    "    db = 2 * (y_pred - y).mean()\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "loss의 수렴 정도를 실험하기 위해서 조절해 본 hyperparameters\n",
    "- Learning rate : 1. 0.01, 0.0001\n",
    "- EPOCHS : 100, 1000, 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATES = [1, 0.01, 0.001]\n",
    "EPOCHS = [100, 1000, 10000]\n",
    "\n",
    "losses_set = {}\n",
    "params_set = {}\n",
    "\n",
    "for i in range(len(EPOCHS)):\n",
    "    for j in range(len(LEARNING_RATES)):\n",
    "        # W, b 초기화\n",
    "        W = np.zeros(X_train.shape[1])\n",
    "        b = np.random.rand()\n",
    "        \n",
    "        # 개별 학습 손실 추적\n",
    "        losses = []\n",
    "        \n",
    "        for k in range(1, EPOCHS[i] + 1):  # EPOCHS[i] 반복\n",
    "            dW, db = gradient(X_train, W, b, y_train)\n",
    "            W -= LEARNING_RATES[j] * dW\n",
    "            b -= LEARNING_RATES[j] * db\n",
    "            L = loss(X_train, W, b, y_train)\n",
    "            losses.append(L)\n",
    "            \n",
    "            if k % 1000 == 0:\n",
    "                print(f\"EPOCH {EPOCHS[i]}, LR {LEARNING_RATES[j]} - Iteration {k}: Loss {L:.4f}\")\n",
    "\n",
    "        # 최종 손실 저장\n",
    "        losses_set[f\"EPOCHS: {EPOCHS[i]}, LEARNING: {LEARNING_RATES[j]}\"] = losses\n",
    "        # 최종 파라미터 저장\n",
    "        params_set[f\"EPOCHS: {EPOCHS[i]}, LEARNING: {LEARNING_RATES[j]}\"] = (W, b)\n",
    "\n",
    "print(\"Finish training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses_set.keys())\n",
    "print(params_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for key, losses in losses_set.items():\n",
    "    plt.plot(losses, label=key)\n",
    "\n",
    "plt.title(\"Losses Over Iterations for Different Hyperparameters\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "    \n",
    "for key, (W, b) in params_set.items():\n",
    "    prediction = model(X_test, W, b)  # 예측값 계산\n",
    "    plt.scatter(X_test[:, 0], prediction, label=f\"Prediction ({key})\", alpha=0.6)\n",
    "\n",
    "# 실제값 추가\n",
    "plt.scatter(X_test[:, 0], y_test, color='blue', label='Actual', marker='x')\n",
    "\n",
    "# 그래프 설정\n",
    "plt.title(\"Actual vs Predicted Values for Different Hyperparameters\")\n",
    "plt.xlabel(\"Feature: X_test[:, 0]\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
